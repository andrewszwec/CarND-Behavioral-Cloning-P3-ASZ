{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 Behavioural Cloning\n",
    "## Background\n",
    "\n",
    "\n",
    "## Rationale\n",
    "\n",
    "## Plan\n",
    "\n",
    "## Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended Flipping\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Cropping2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepImage(path):\n",
    "    source_path = path\n",
    "    filename = source_path.split('/')[-1]\n",
    "    current_path = './data/IMG/' + filename\n",
    "    return cv2.imread(current_path, 1) # 0 = grayscale, 1 = Colour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lines = []\n",
    "with open('./data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "lines = lines[1:]\n",
    "        \n",
    "images = []\n",
    "measurements = []\n",
    "for line in lines:\n",
    "    # IMAGES\n",
    "    img_center = prepImage(line[0])\n",
    "    images.append(img_center)\n",
    "    \n",
    "    img_left = prepImage(line[1])\n",
    "    images.append(img_left)\n",
    "    \n",
    "    img_right = prepImage(line[2])\n",
    "    images.append(img_right)\n",
    "    \n",
    "    # STEERING\n",
    "    steering_center = float(line[3])\n",
    "    measurements.append(steering_center)\n",
    "    \n",
    "    correction = 0.2 # this is a parameter to tune\n",
    "    steering_left = steering_center + correction\n",
    "    measurements.append(steering_left)\n",
    "    steering_right = steering_center - correction\n",
    "    measurements.append(steering_right)\n",
    "    \n",
    "        \n",
    "# X_train = np.array(images)\n",
    "# y_train = np.array(measurements)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "# Flip the Images for more data   \n",
    "augmented_images, augmented_measurements = [] ,[]\n",
    "for image, measurement in zip(images, measurements ):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurements.append(measurement)\n",
    "    augmented_images.append(cv2.flip(image, 1))\n",
    "    augmented_measurements.append(measurement*-1.0)  \n",
    "        \n",
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurements)   \n",
    "\n",
    "del(images)\n",
    "del(measurements)\n",
    "del(augmented_images)\n",
    "del(augmented_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.405977744"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(X_train) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # ## Split into train and validation\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# # Create Data Generator\n",
    "# datagen = ImageDataGenerator(\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True) #,\n",
    "#     #rotation_range=20, # Could cause an issue for steering\n",
    "#     #width_shift_range=0.2, \n",
    "#     #height_shift_range=0.2 ) #,\n",
    "#     # horizontal_flip=True) # need to flip steering too\n",
    "\n",
    "# # compute quantities required for featurewise normalization\n",
    "# # (std, mean, and principal components if ZCA whitening is applied)\n",
    "# datagen.fit(X_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Recommended Flipping\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Cropping2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASIC MODEL (No Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38572 samples, validate on 9644 samples\n",
      "Epoch 1/10\n",
      "38572/38572 [==============================] - 68s - loss: 0.0176 - val_loss: 0.0119\n",
      "Epoch 2/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 3/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 4/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 5/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 6/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 7/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 8/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0085 - val_loss: 0.0106\n",
      "Epoch 9/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0083 - val_loss: 0.0101\n",
      "Epoch 10/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0082 - val_loss: 0.0107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f52dfebbfd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=5),\n",
    "    ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True, verbose=0)\n",
    "]\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "learn_rate = 0.001\n",
    "drop_rate = 0.3\n",
    "\n",
    "model = Sequential()\n",
    "# Normalise\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "# Crop\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(3,160,320)))\n",
    "\n",
    "# Conv Layer 1\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "# Conv Layer 2\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "# Conv Layer 3\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(drop_rate))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=learn_rate))\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history_object = model.fit(X_train, \n",
    "          y_train, \n",
    "          validation_split=0.2,\n",
    "          shuffle=True,\n",
    "          epochs=epochs,\n",
    "          callbacks=callbacks)\n",
    "\n",
    "# Save model in callbacks\n",
    "# model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do some plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Level Model (Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepImage(path, img_dir):\n",
    "    filename = path.split('/')[-1]\n",
    "    current_path = img_dir + filename\n",
    "    return cv2.imread(current_path, 1) # 0 = grayscale, 1 = Colour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# driving_log = './data/driving_log.csv'\n",
    "# img_dir = './data/IMG/'\n",
    "driving_log = './car_training_data/driving_log.csv'\n",
    "img_dir = './car_training_data/IMG/'\n",
    "\n",
    "samples = []\n",
    "with open(driving_log) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Hyperparameters - leave these in this position\n",
    "batch_size = 256\n",
    "epochs = 15\n",
    "learn_rate = 0.001\n",
    "drop_rate = 0.3\n",
    "\n",
    "## Add multi camera angels (left/right) + Augmentation# Flip the Images for more data   \n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    batch_size = batch_size // 2 # to deal with image augmentation\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                \n",
    "                # IMAGES\n",
    "                img_center = prepImage(batch_sample[0], img_dir)\n",
    "                images.append(img_center)\n",
    "                \n",
    "                img_left = prepImage(batch_sample[1], img_dir)\n",
    "                images.append(img_left)\n",
    "                \n",
    "                img_right = prepImage(batch_sample[2], img_dir)\n",
    "                images.append(img_right)\n",
    "                \n",
    "                \n",
    "                # STEERING\n",
    "                steering_center = float(batch_sample[3])\n",
    "                angles.append(steering_center)\n",
    "\n",
    "                correction = 0.2 # this is a parameter to tune\n",
    "                steering_left = steering_center + correction\n",
    "                angles.append(steering_left)\n",
    "                steering_right = steering_center - correction\n",
    "                angles.append(steering_right)\n",
    "        \n",
    "            # AUGMENTATION (Flip the Images for more data)\n",
    "            augmented_images = []\n",
    "            augmented_angles = [] \n",
    "            for image, angle in zip(images, angles):\n",
    "                augmented_images.append(image)\n",
    "                augmented_angles.append(angle)\n",
    "                augmented_images.append(cv2.flip(image, 1))\n",
    "                augmented_angles.append(angle*-1.0)  \n",
    "\n",
    "            X_train = np.array(augmented_images)\n",
    "            y_train = np.array(augmented_angles)\n",
    "            \n",
    "            yield shuffle(X_train, y_train)\n",
    "            \n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=batch_size)\n",
    "validation_generator = generator(validation_samples, batch_size=batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Working code with left, right and centre images\n",
    "##\n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import sklearn\n",
    "# from sklearn.utils import shuffle\n",
    "\n",
    "# # Hyperparameters - leave these in this position\n",
    "# batch_size = 256\n",
    "# epochs = 5\n",
    "# learn_rate = 0.001\n",
    "# drop_rate = 0.3\n",
    "\n",
    "# ## Add multi camera angels (left/right) + Augmentation# Flip the Images for more data   \n",
    "\n",
    "# def generator(samples, batch_size=32):\n",
    "#     num_samples = len(samples)\n",
    "#     while 1: # Loop forever so the generator never terminates\n",
    "#         shuffle(samples)\n",
    "#         for offset in range(0, num_samples, batch_size):\n",
    "#             batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "#             images = []\n",
    "#             angles = []\n",
    "#             for batch_sample in batch_samples:\n",
    "                \n",
    "#                 # IMAGES\n",
    "#                 img_center = prepImage(batch_sample[0], img_dir)\n",
    "#                 images.append(img_center)\n",
    "                \n",
    "#                 img_left = prepImage(batch_sample[1], img_dir)\n",
    "#                 images.append(img_left)\n",
    "                \n",
    "#                 img_right = prepImage(batch_sample[2], img_dir)\n",
    "#                 images.append(img_right)\n",
    "                \n",
    "                \n",
    "#                 # STEERING\n",
    "#                 steering_center = float(batch_sample[3])\n",
    "#                 angles.append(steering_center)\n",
    "\n",
    "#                 correction = 0.2 # this is a parameter to tune\n",
    "#                 steering_left = steering_center + correction\n",
    "#                 angles.append(steering_left)\n",
    "#                 steering_right = steering_center - correction\n",
    "#                 angles.append(steering_right)\n",
    "\n",
    "\n",
    "#             # trim image to only see section with road\n",
    "#             X_train = np.array(images)\n",
    "#             y_train = np.array(angles)\n",
    "            \n",
    "#             yield shuffle(X_train, y_train)\n",
    "            \n",
    "# # compile and train the model using the generator function\n",
    "# train_generator = generator(train_samples, batch_size=batch_size)\n",
    "# validation_generator = generator(validation_samples, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Working code with centre images\n",
    "##\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import sklearn\n",
    "# from sklearn.utils import shuffle\n",
    "\n",
    "# # Hyperparameters - leave these in this position\n",
    "# batch_size = 256\n",
    "# epochs = 10\n",
    "# learn_rate = 0.001\n",
    "# drop_rate = 0.3\n",
    "\n",
    "# ## Add multi camera angels (left/right) + Augmentation# Flip the Images for more data   \n",
    "\n",
    "# def generator(samples, batch_size=32):\n",
    "#     num_samples = len(samples)\n",
    "#     while 1: # Loop forever so the generator never terminates\n",
    "#         shuffle(samples)\n",
    "#         for offset in range(0, num_samples, batch_size):\n",
    "#             batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "#             images = []\n",
    "#             angles = []\n",
    "#             for batch_sample in batch_samples:\n",
    "#                 name = img_dir + batch_sample[0].split('/')[-1]\n",
    "#                 # Update this for all camera angles\n",
    "#                 center_image = cv2.imread(name, 1) # 0 = grayscale, 1 = Colour\n",
    "#                 center_angle = float(batch_sample[3])\n",
    "#                 images.append(center_image)\n",
    "#                 angles.append(center_angle)\n",
    "\n",
    "#             # trim image to only see section with road\n",
    "#             X_train = np.array(images)\n",
    "#             y_train = np.array(angles)\n",
    "#             yield shuffle(X_train, y_train)\n",
    "            \n",
    "# # compile and train the model using the generator function\n",
    "# train_generator = generator(train_samples, batch_size=batch_size)\n",
    "# validation_generator = generator(validation_samples, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "110/109 [==============================] - 175s - loss: 0.0574 - val_loss: 0.0525\n",
      "Epoch 2/15\n",
      "110/109 [==============================] - 163s - loss: 0.0414 - val_loss: 0.0393\n",
      "Epoch 3/15\n",
      "110/109 [==============================] - 163s - loss: 0.0281 - val_loss: 0.0297\n",
      "Epoch 4/15\n",
      "110/109 [==============================] - 164s - loss: 0.0225 - val_loss: 0.0261\n",
      "Epoch 5/15\n",
      "110/109 [==============================] - 164s - loss: 0.0192 - val_loss: 0.0212\n",
      "Epoch 6/15\n",
      "110/109 [==============================] - 164s - loss: 0.0168 - val_loss: 0.0183\n",
      "Epoch 7/15\n",
      "110/109 [==============================] - 164s - loss: 0.0146 - val_loss: 0.0167\n",
      "Epoch 8/15\n",
      "110/109 [==============================] - 164s - loss: 0.0137 - val_loss: 0.0141\n",
      "Epoch 9/15\n",
      "110/109 [==============================] - 164s - loss: 0.0131 - val_loss: 0.0133\n",
      "Epoch 10/15\n",
      "110/109 [==============================] - 164s - loss: 0.0124 - val_loss: 0.0131\n",
      "Epoch 11/15\n",
      "110/109 [==============================] - 164s - loss: 0.0120 - val_loss: 0.0128\n",
      "Epoch 12/15\n",
      "110/109 [==============================] - 164s - loss: 0.0117 - val_loss: 0.0123\n",
      "Epoch 13/15\n",
      "110/109 [==============================] - 164s - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 14/15\n",
      "110/109 [==============================] - 164s - loss: 0.0104 - val_loss: 0.0117\n",
      "Epoch 15/15\n",
      "110/109 [==============================] - 164s - loss: 0.0102 - val_loss: 0.0098\n"
     ]
    }
   ],
   "source": [
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=5),\n",
    "    ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True, verbose=0)\n",
    "]\n",
    "\n",
    "img_h, img_w, ch = 160, 320, 3\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# # Normalise\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(img_h,img_w,ch)))\n",
    "# Crop\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)) )) # , input_shape=(3,160,320)))\n",
    "\n",
    "# Conv Layer 1\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same')) # filters = 8\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "# Conv Layer 2\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same')) # filters = 16\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "# Conv Layer 3\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same')) # filters = 32\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "# Conv Layer 4\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same')) # filters = 64\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(drop_rate))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=learn_rate))\n",
    "\n",
    "history_object = model.fit_generator(train_generator,\n",
    "                    # num train samples * 3 for centre, left, right camera, *2 for augmentation\n",
    "                    steps_per_epoch= (len(train_samples)*3*2) / batch_size, \n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps= (len(validation_samples)*3*2) / batch_size, \n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEZCAYAAACEkhK6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f56b2bbf2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.27734375"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_samples)/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
