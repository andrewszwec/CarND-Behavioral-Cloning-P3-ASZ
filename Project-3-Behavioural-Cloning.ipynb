{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 Behavioural Cloning\n",
    "## Background\n",
    "\n",
    "\n",
    "## Rationale\n",
    "\n",
    "## Plan\n",
    "\n",
    "## Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recommended Flipping\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Cropping2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepImage(path):\n",
    "    source_path = path\n",
    "    filename = source_path.split('/')[-1]\n",
    "    current_path = './data/IMG/' + filename\n",
    "    return cv2.imread(current_path, 1) # 0 = grayscale, 1 = Colour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lines = []\n",
    "with open('./data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "lines = lines[1:]\n",
    "        \n",
    "images = []\n",
    "measurements = []\n",
    "for line in lines:\n",
    "    # IMAGES\n",
    "    img_center = prepImage(line[0])\n",
    "    images.append(img_center)\n",
    "    \n",
    "    img_left = prepImage(line[1])\n",
    "    images.append(img_left)\n",
    "    \n",
    "    img_right = prepImage(line[2])\n",
    "    images.append(img_right)\n",
    "    \n",
    "    # STEERING\n",
    "    steering_center = float(line[3])\n",
    "    measurements.append(steering_center)\n",
    "    \n",
    "    correction = 0.2 # this is a parameter to tune\n",
    "    steering_left = steering_center + correction\n",
    "    measurements.append(steering_left)\n",
    "    steering_right = steering_center - correction\n",
    "    measurements.append(steering_right)\n",
    "    \n",
    "        \n",
    "# X_train = np.array(images)\n",
    "# y_train = np.array(measurements)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "# Flip the Images for more data   \n",
    "augmented_images, augmented_measurements = [] ,[]\n",
    "for image, measurement in zip(images, measurements ):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurements.append(measurement)\n",
    "    augmented_images.append(cv2.flip(image, 1))\n",
    "    augmented_measurements.append(measurement*-1.0)  \n",
    "        \n",
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurements)   \n",
    "\n",
    "del(images)\n",
    "del(measurements)\n",
    "del(augmented_images)\n",
    "del(augmented_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.405977744"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(X_train) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # ## Split into train and validation\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# # Create Data Generator\n",
    "# datagen = ImageDataGenerator(\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True) #,\n",
    "#     #rotation_range=20, # Could cause an issue for steering\n",
    "#     #width_shift_range=0.2, \n",
    "#     #height_shift_range=0.2 ) #,\n",
    "#     # horizontal_flip=True) # need to flip steering too\n",
    "\n",
    "# # compute quantities required for featurewise normalization\n",
    "# # (std, mean, and principal components if ZCA whitening is applied)\n",
    "# datagen.fit(X_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Recommended Flipping\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Cropping2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASIC MODEL (No Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38572 samples, validate on 9644 samples\n",
      "Epoch 1/10\n",
      "38572/38572 [==============================] - 68s - loss: 0.0176 - val_loss: 0.0119\n",
      "Epoch 2/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 3/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 4/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 5/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 6/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 7/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 8/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0085 - val_loss: 0.0106\n",
      "Epoch 9/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0083 - val_loss: 0.0101\n",
      "Epoch 10/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0082 - val_loss: 0.0107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f52dfebbfd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=5),\n",
    "    ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True, verbose=0)\n",
    "]\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "learn_rate = 0.001\n",
    "drop_rate = 0.3\n",
    "\n",
    "model = Sequential()\n",
    "# Normalise\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "# Crop\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(3,160,320)))\n",
    "\n",
    "# Conv Layer 1\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "# Conv Layer 2\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "# Conv Layer 3\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(drop_rate))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=learn_rate))\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history_object = model.fit(X_train, \n",
    "          y_train, \n",
    "          validation_split=0.2,\n",
    "          shuffle=True,\n",
    "          epochs=epochs,\n",
    "          callbacks=callbacks)\n",
    "\n",
    "# Save model in callbacks\n",
    "# model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do some plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Level Model (Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# driving_log = './data/driving_log.csv'\n",
    "# img_dir = './data/IMG/'\n",
    "# driving_log = './car_training_data/driving_log.csv'\n",
    "# img_dir = './car_training_data/IMG/'\n",
    "driving_log = './data/driving_log_combined.csv'\n",
    "img_dir = './data/IMG/'\n",
    "\n",
    "samples = []\n",
    "with open(driving_log) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    # Skip header row\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepImage(path, img_dir):\n",
    "    filename = path.split('/')[-1]\n",
    "    current_path = img_dir + filename\n",
    "    return cv2.imread(current_path, 1) # 0 = grayscale, 1 = Colour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Hyperparameters - leave these in this position\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "learn_rate = 0.0001\n",
    "drop_rate = 0.3\n",
    "\n",
    "## Add multi camera angels (left/right) + Augmentation# Flip the Images for more data   \n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    batch_size = batch_size // 2 # to deal with image augmentation\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                \n",
    "                # IMAGES\n",
    "                img_center = prepImage(batch_sample[0], img_dir)\n",
    "                images.append(img_center)\n",
    "                \n",
    "                img_left = prepImage(batch_sample[1], img_dir)\n",
    "                images.append(img_left)\n",
    "                \n",
    "                img_right = prepImage(batch_sample[2], img_dir)\n",
    "                images.append(img_right)\n",
    "                \n",
    "                \n",
    "                # STEERING\n",
    "                steering_center = float(batch_sample[3])\n",
    "                angles.append(steering_center)\n",
    "\n",
    "                correction = 1.0 # this is a parameter to tune 0.2\n",
    "                steering_left = steering_center + correction\n",
    "                angles.append(steering_left)\n",
    "                steering_right = steering_center - correction\n",
    "                angles.append(steering_right)\n",
    "        \n",
    "            # AUGMENTATION (Flip the Images for more data)\n",
    "            augmented_images = []\n",
    "            augmented_angles = [] \n",
    "            for image, angle in zip(images, angles):\n",
    "                augmented_images.append(image)\n",
    "                augmented_angles.append(angle)\n",
    "                augmented_images.append(cv2.flip(image, 1))\n",
    "                augmented_angles.append(angle*-1.0)  \n",
    "\n",
    "            X_train = np.array(augmented_images)\n",
    "            y_train = np.array(augmented_angles)\n",
    "            \n",
    "            yield shuffle(X_train, y_train)\n",
    "            \n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=batch_size)\n",
    "validation_generator = generator(validation_samples, batch_size=batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "87/86 [==============================] - 77s - loss: 0.6336 - val_loss: 0.5582\n",
      "Epoch 2/10\n",
      "87/86 [==============================] - 76s - loss: 0.5280 - val_loss: 0.4972\n",
      "Epoch 3/10\n",
      "87/86 [==============================] - 76s - loss: 0.4775 - val_loss: 0.4647\n",
      "Epoch 4/10\n",
      "87/86 [==============================] - 76s - loss: 0.4484 - val_loss: 0.4442\n",
      "Epoch 5/10\n",
      "87/86 [==============================] - 76s - loss: 0.4293 - val_loss: 0.4303\n",
      "Epoch 6/10\n",
      "87/86 [==============================] - 76s - loss: 0.4188 - val_loss: 0.4267\n",
      "Epoch 7/10\n",
      "87/86 [==============================] - 76s - loss: 0.4116 - val_loss: 0.4220\n",
      "Epoch 8/10\n",
      "87/86 [==============================] - 76s - loss: 0.4065 - val_loss: 0.4214\n",
      "Epoch 9/10\n",
      "87/86 [==============================] - 76s - loss: 0.4003 - val_loss: 0.4137\n",
      "Epoch 10/10\n",
      "87/86 [==============================] - 76s - loss: 0.3953 - val_loss: 0.4121\n"
     ]
    }
   ],
   "source": [
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5),\n",
    "    ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True, verbose=0)\n",
    "]\n",
    "\n",
    "img_h, img_w, ch = 160, 320, 3 \n",
    "top_crop, bottom_crop = 50, 20\n",
    "left_crop, right_crop = 0, 0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Normalise\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(img_h,img_w,ch)))\n",
    "# Crop\n",
    "model.add(Cropping2D(cropping=((top_crop, bottom_crop), (left_crop, right_crop)) )) # , input_shape=(3,160,320)))\n",
    "# Add Random Noise - Prevents overfitting\n",
    "#model.add( GaussianNoise(stddev=1.0) )\n",
    "\n",
    "\n",
    "# Conv Layer 1\n",
    "model.add(Conv2D(24, (3, 3), strides=(2,2), activation='relu', padding='same')) # filters = 8\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "# Conv Layer 2\n",
    "model.add(Conv2D(36, (3, 3), strides=(2,2), activation='relu', padding='same')) # filters = 16\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "# Conv Layer 3\n",
    "model.add(Conv2D(48, (3, 3), strides=(1,1), activation='relu', padding='same')) # filters = 32\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "# Conv Layer 4\n",
    "model.add(Conv2D(64, (3, 3), strides=(1,1), activation='relu', padding='same')) # filters = 64\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "#model.add(Dropout(drop_rate))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=learn_rate))\n",
    "\n",
    "# num train samples * 3 for centre, left, right camera, *2 for augmentation\n",
    "batch_step_factor = 2 #3*2 # Need 3*2 to use full dataset each epoch\n",
    "\n",
    "history_object = model.fit_generator(train_generator,\n",
    "                    # num train samples * 3 for centre, left, right camera, *2 for augmentation\n",
    "                    steps_per_epoch= (len(train_samples)*batch_step_factor) / batch_size, \n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps= (len(validation_samples)*batch_step_factor) / batch_size, \n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEZCAYAAABiu9n+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxgRkScIYY0xAliSMMcYE9P+QxC8HECMSZAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84af2cbe80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Working code with left, right and centre images\n",
    "##\n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import sklearn\n",
    "# from sklearn.utils import shuffle\n",
    "\n",
    "# # Hyperparameters - leave these in this position\n",
    "# batch_size = 256\n",
    "# epochs = 5\n",
    "# learn_rate = 0.001\n",
    "# drop_rate = 0.3\n",
    "\n",
    "# ## Add multi camera angels (left/right) + Augmentation# Flip the Images for more data   \n",
    "\n",
    "# def generator(samples, batch_size=32):\n",
    "#     num_samples = len(samples)\n",
    "#     while 1: # Loop forever so the generator never terminates\n",
    "#         shuffle(samples)\n",
    "#         for offset in range(0, num_samples, batch_size):\n",
    "#             batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "#             images = []\n",
    "#             angles = []\n",
    "#             for batch_sample in batch_samples:\n",
    "                \n",
    "#                 # IMAGES\n",
    "#                 img_center = prepImage(batch_sample[0], img_dir)\n",
    "#                 images.append(img_center)\n",
    "                \n",
    "#                 img_left = prepImage(batch_sample[1], img_dir)\n",
    "#                 images.append(img_left)\n",
    "                \n",
    "#                 img_right = prepImage(batch_sample[2], img_dir)\n",
    "#                 images.append(img_right)\n",
    "                \n",
    "                \n",
    "#                 # STEERING\n",
    "#                 steering_center = float(batch_sample[3])\n",
    "#                 angles.append(steering_center)\n",
    "\n",
    "#                 correction = 0.2 # this is a parameter to tune\n",
    "#                 steering_left = steering_center + correction\n",
    "#                 angles.append(steering_left)\n",
    "#                 steering_right = steering_center - correction\n",
    "#                 angles.append(steering_right)\n",
    "\n",
    "\n",
    "#             # trim image to only see section with road\n",
    "#             X_train = np.array(images)\n",
    "#             y_train = np.array(angles)\n",
    "            \n",
    "#             yield shuffle(X_train, y_train)\n",
    "            \n",
    "# # compile and train the model using the generator function\n",
    "# train_generator = generator(train_samples, batch_size=batch_size)\n",
    "# validation_generator = generator(validation_samples, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Working code with centre images\n",
    "##\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import sklearn\n",
    "# from sklearn.utils import shuffle\n",
    "\n",
    "# # Hyperparameters - leave these in this position\n",
    "# batch_size = 256\n",
    "# epochs = 10\n",
    "# learn_rate = 0.001\n",
    "# drop_rate = 0.3\n",
    "\n",
    "# ## Add multi camera angels (left/right) + Augmentation# Flip the Images for more data   \n",
    "\n",
    "# def generator(samples, batch_size=32):\n",
    "#     num_samples = len(samples)\n",
    "#     while 1: # Loop forever so the generator never terminates\n",
    "#         shuffle(samples)\n",
    "#         for offset in range(0, num_samples, batch_size):\n",
    "#             batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "#             images = []\n",
    "#             angles = []\n",
    "#             for batch_sample in batch_samples:\n",
    "#                 name = img_dir + batch_sample[0].split('/')[-1]\n",
    "#                 # Update this for all camera angles\n",
    "#                 center_image = cv2.imread(name, 1) # 0 = grayscale, 1 = Colour\n",
    "#                 center_angle = float(batch_sample[3])\n",
    "#                 images.append(center_image)\n",
    "#                 angles.append(center_angle)\n",
    "\n",
    "#             # trim image to only see section with road\n",
    "#             X_train = np.array(images)\n",
    "#             y_train = np.array(angles)\n",
    "#             yield shuffle(X_train, y_train)\n",
    "            \n",
    "# # compile and train the model using the generator function\n",
    "# train_generator = generator(train_samples, batch_size=batch_size)\n",
    "# validation_generator = generator(validation_samples, batch_size=batch_size)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
