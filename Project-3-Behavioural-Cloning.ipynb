{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 Behavioural Cloning\n",
    "## Background\n",
    "\n",
    "\n",
    "## Rationale\n",
    "\n",
    "## Plan\n",
    "\n",
    "## Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepImage(path):\n",
    "    source_path = path\n",
    "    filename = source_path.split('/')[-1]\n",
    "    current_path = './data/IMG/' + filename\n",
    "    return cv2.imread(current_path, 1) # 0 = grayscale, 1 = Colour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lines = []\n",
    "with open('./data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "lines = lines[1:]\n",
    "        \n",
    "images = []\n",
    "measurements = []\n",
    "for line in lines:\n",
    "    # IMAGES\n",
    "    img_center = prepImage(line[0])\n",
    "    images.append(img_center)\n",
    "    \n",
    "    img_left = prepImage(line[1])\n",
    "    images.append(img_left)\n",
    "    \n",
    "    img_right = prepImage(line[2])\n",
    "    images.append(img_right)\n",
    "    \n",
    "    # STEERING\n",
    "    steering_center = float(line[3])\n",
    "    measurements.append(steering_center)\n",
    "    \n",
    "    correction = 0.2 # this is a parameter to tune\n",
    "    steering_left = steering_center + correction\n",
    "    measurements.append(steering_left)\n",
    "    steering_right = steering_center - correction\n",
    "    measurements.append(steering_right)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv_file = './data/driving_log.csv'\n",
    "# car_images = []\n",
    "# steering_angles = []\n",
    "# with open(csv_file, 'r') as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     next(reader, None)  # skip the headers\n",
    "#     for row in reader:\n",
    "#         steering_center = float(row[3])\n",
    "\n",
    "#         # create adjusted steering measurements for the side camera images\n",
    "#         correction = 0.2 # this is a parameter to tune\n",
    "#         steering_left = steering_center + correction\n",
    "#         steering_right = steering_center - correction\n",
    "\n",
    "#         # read in images from center, left and right cameras\n",
    "#         path = './data/' # fill in the path to your training IMG directory\n",
    "#         img_center = process_image(np.asarray(Image.open(path + row[0].replace(' ',''))))\n",
    "#         img_left = process_image(np.asarray(Image.open(path + row[1].replace(' ',''))))\n",
    "#         img_right = process_image(np.asarray(Image.open(path + row[2].replace(' ',''))))\n",
    "\n",
    "#         # add images and angles to data set\n",
    "#         car_images.extend(img_center)\n",
    "#         car_images.extend(img_left)\n",
    "#         car_images.extend(img_right)\n",
    "#         steering_angles.extend(steering_center)\n",
    "#         steering_angles.extend(steering_left)\n",
    "#         steering_angles.extend(steering_right)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# Flip the Images for more data   \n",
    "augmented_images, augmented_measurements = [] ,[]\n",
    "for image, measurement in zip(images, measurements ):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurements.append(measurement)\n",
    "    augmented_images.append(cv2.flip(image, 1))\n",
    "    augmented_measurements.append(measurement*-1.0)  \n",
    "        \n",
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurements)   \n",
    "\n",
    "del(images)\n",
    "del(measurements)\n",
    "del(augmented_images)\n",
    "del(augmented_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e8752bced7bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1e9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(X_train) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Backup\n",
    "# lines = []\n",
    "# with open('./data/driving_log.csv') as csvfile:\n",
    "#     reader = csv.reader(csvfile)\n",
    "#     for line in reader:\n",
    "#         lines.append(line)\n",
    "\n",
    "# lines = lines[1:]\n",
    "        \n",
    "# images = []\n",
    "# measurements = []\n",
    "# for line in lines:\n",
    "#     source_path = line[0]\n",
    "#     filename = source_path.split('/')[-1]\n",
    "#     current_path = './data/IMG/' + filename\n",
    "#     image = cv2.imread(current_path, 1) # 0 = grayscale, 1 = Colour\n",
    "    \n",
    "#     # Preprocess with CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "#     # http://docs.opencv.org/3.1.0/d5/daf/tutorial_py_histogram_equalization.html\n",
    "# #     clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "# #     image = clahe.apply(image)\n",
    "    \n",
    "#     images.append(image)\n",
    "#     measurement = float(line[3])\n",
    "#     measurements.append(measurement)\n",
    "    \n",
    "# X_train = np.array(images)\n",
    "# y_train = np.array(measurements)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Split into train and validation\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 160, 320\n",
    "# Colour\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "# Grayscale\n",
    "#input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FIX  RANK <4 issue\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "    \n",
    "img = X_train[0]\n",
    "imgplot = plt.imshow(img)\n",
    "\n",
    "X_train = X_train.astype('float32').reshape((5625, 160, 320, 3))\n",
    "X_valid = X_valid.astype('float32').reshape((2411, 160, 320, 3))\n",
    "# X_train /= 255\n",
    "# X_valid /= 255\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_valid.shape[0], 'validation samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Save Processed Data\n",
    "# import pickle\n",
    "# with open('X_train.p','wb') as myfile:\n",
    "#     pickle.dump(X_train, myfile)   \n",
    "\n",
    "# with open('X_valid.p','wb') as myfile:\n",
    "#     pickle.dump(X_valid, myfile)   \n",
    "    \n",
    "# with open('y_train.p','wb') as myfile:\n",
    "#     pickle.dump(y_train, myfile)  \n",
    "\n",
    "# with open('y_valid.p','wb') as myfile:\n",
    "#     pickle.dump(y_valid, myfile)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fb137c5db7e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# compute quantities required for featurewise normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# (std, mean, and principal components if ZCA whitening is applied)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, augment, rounds, seed)\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mof\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0minput\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \"\"\"\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             raise ValueError('Input to `.fit()` should have rank 4. '\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create Data Generator\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True) #,\n",
    "    #rotation_range=20, # Could cause an issue for steering\n",
    "    #width_shift_range=0.2, \n",
    "    #height_shift_range=0.2 ) #,\n",
    "    # horizontal_flip=True) # need to flip steering too\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recommended Flipping\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Cropping2D\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EarlyStopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-182256e0d04c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m callbacks = [\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ]\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=5),\n",
    "    ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True, verbose=0)\n",
    "]\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 5\n",
    "learn_rate = 0.001\n",
    "drop_rate = 0.3\n",
    "\n",
    "model = Sequential()\n",
    "# Normalise\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "# Crop\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(3,160,320)))\n",
    "\n",
    "# Conv Layer 1\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "# Conv Layer 2\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "# Conv Layer 3\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(drop_rate))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=learn_rate))\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(generator=datagen.flow(X_train, y_train, batch_size=batch_size), \n",
    "                    validation_data=datagen.flow(X_valid, y_valid, batch_size=batch_size),\n",
    "                    #validation_split=0.2,\n",
    "                    shuffle=True,\n",
    "                    steps_per_epoch=len(X_train) / batch_size, \n",
    "                    validation_steps=len(X_valid) / batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "# Save model in callbacks\n",
    "# model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## BACKUP\n",
    "# callbacks = [\n",
    "#     EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=5),\n",
    "#     ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True, verbose=0)\n",
    "# ]\n",
    "\n",
    "# batch_size = 256\n",
    "# epochs = 5\n",
    "# learn_rate = 0.001\n",
    "# drop_rate = 0.3\n",
    "\n",
    "# model = Sequential()\n",
    "# # Normalise\n",
    "# model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "# # Crop\n",
    "# model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(3,160,320)))\n",
    "\n",
    "# # Conv Layer 1\n",
    "# model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(drop_rate))\n",
    "\n",
    "# # Conv Layer 2\n",
    "# model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(drop_rate))\n",
    "\n",
    "# # Conv Layer 3\n",
    "# model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(drop_rate))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(drop_rate))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=learn_rate))\n",
    "\n",
    "# # Model without Image Augmentation\n",
    "# # model.fit(X_train, y_train,\n",
    "# #           batch_size=batch_size,\n",
    "# #           epochs=epochs,\n",
    "# #           verbose=1,\n",
    "# #           validation_data=(X_valid, y_valid),\n",
    "# #           shuffle=True,\n",
    "# #           callbacks=callbacks)\n",
    "# # model.save('model.h5')\n",
    "\n",
    "# # fits the model on batches with real-time data augmentation:\n",
    "# model.fit_generator(generator=datagen.flow(X_train, y_train, batch_size=batch_size), \n",
    "#                     validation_data=datagen.flow(X_valid, y_valid, batch_size=batch_size),\n",
    "#                     steps_per_epoch=len(X_train) / batch_size, \n",
    "#                     validation_steps=len(X_valid) / batch_size,\n",
    "#                     epochs=epochs,\n",
    "#                     callbacks=callbacks)\n",
    "\n",
    "# # Save model in callbacks\n",
    "# # model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
