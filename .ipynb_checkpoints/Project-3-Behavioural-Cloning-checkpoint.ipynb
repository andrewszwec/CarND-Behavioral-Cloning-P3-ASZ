{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 Behavioural Cloning\n",
    "## Background\n",
    "\n",
    "\n",
    "## Rationale\n",
    "\n",
    "## Plan\n",
    "\n",
    "## Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recommended Flipping\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Cropping2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepImage(path):\n",
    "    source_path = path\n",
    "    filename = source_path.split('/')[-1]\n",
    "    current_path = './data/IMG/' + filename\n",
    "    return cv2.imread(current_path, 1) # 0 = grayscale, 1 = Colour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lines = []\n",
    "with open('./data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "lines = lines[1:]\n",
    "        \n",
    "images = []\n",
    "measurements = []\n",
    "for line in lines:\n",
    "    # IMAGES\n",
    "    img_center = prepImage(line[0])\n",
    "    images.append(img_center)\n",
    "    \n",
    "    img_left = prepImage(line[1])\n",
    "    images.append(img_left)\n",
    "    \n",
    "    img_right = prepImage(line[2])\n",
    "    images.append(img_right)\n",
    "    \n",
    "    # STEERING\n",
    "    steering_center = float(line[3])\n",
    "    measurements.append(steering_center)\n",
    "    \n",
    "    correction = 0.2 # this is a parameter to tune\n",
    "    steering_left = steering_center + correction\n",
    "    measurements.append(steering_left)\n",
    "    steering_right = steering_center - correction\n",
    "    measurements.append(steering_right)\n",
    "    \n",
    "        \n",
    "# X_train = np.array(images)\n",
    "# y_train = np.array(measurements)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "# Flip the Images for more data   \n",
    "augmented_images, augmented_measurements = [] ,[]\n",
    "for image, measurement in zip(images, measurements ):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurements.append(measurement)\n",
    "    augmented_images.append(cv2.flip(image, 1))\n",
    "    augmented_measurements.append(measurement*-1.0)  \n",
    "        \n",
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurements)   \n",
    "\n",
    "del(images)\n",
    "del(measurements)\n",
    "del(augmented_images)\n",
    "del(augmented_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.405977744"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(X_train) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # ## Split into train and validation\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# # Create Data Generator\n",
    "# datagen = ImageDataGenerator(\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True) #,\n",
    "#     #rotation_range=20, # Could cause an issue for steering\n",
    "#     #width_shift_range=0.2, \n",
    "#     #height_shift_range=0.2 ) #,\n",
    "#     # horizontal_flip=True) # need to flip steering too\n",
    "\n",
    "# # compute quantities required for featurewise normalization\n",
    "# # (std, mean, and principal components if ZCA whitening is applied)\n",
    "# datagen.fit(X_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Recommended Flipping\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Cropping2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASIC MODEL (No Generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38572 samples, validate on 9644 samples\n",
      "Epoch 1/10\n",
      "38572/38572 [==============================] - 68s - loss: 0.0176 - val_loss: 0.0119\n",
      "Epoch 2/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 3/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 4/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 5/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 6/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0089 - val_loss: 0.0105\n",
      "Epoch 7/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 8/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0085 - val_loss: 0.0106\n",
      "Epoch 9/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0083 - val_loss: 0.0101\n",
      "Epoch 10/10\n",
      "38572/38572 [==============================] - 67s - loss: 0.0082 - val_loss: 0.0107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f52dfebbfd0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=5),\n",
    "    ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True, verbose=0)\n",
    "]\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "learn_rate = 0.001\n",
    "drop_rate = 0.3\n",
    "\n",
    "model = Sequential()\n",
    "# Normalise\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "# Crop\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(3,160,320)))\n",
    "\n",
    "# Conv Layer 1\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "# Conv Layer 2\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "# Conv Layer 3\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(drop_rate))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=learn_rate))\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history_object = model.fit(X_train, \n",
    "          y_train, \n",
    "          validation_split=0.2,\n",
    "          shuffle=True,\n",
    "          epochs=epochs,\n",
    "          callbacks=callbacks)\n",
    "\n",
    "# Save model in callbacks\n",
    "# model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do some plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Level Model (Generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepImage(path, img_dir):\n",
    "    filename = path.split('/')[-1]\n",
    "    current_path = img_dir + filename\n",
    "    return cv2.imread(current_path, 1) # 0 = grayscale, 1 = Colour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "driving_log = './data/driving_log.csv'\n",
    "img_dir = './data/IMG/'\n",
    "# driving_log = './car_training_data/driving_log.csv'\n",
    "# img_dir = './car_training_data/IMG/'\n",
    "# driving_log = './data/driving_log_combined.csv'\n",
    "# img_dir = './data/IMG/'\n",
    "\n",
    "samples = []\n",
    "with open(driving_log) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    # Skip header row\n",
    "    next(reader)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Hyperparameters - leave these in this position\n",
    "batch_size = 256\n",
    "epochs = 5\n",
    "learn_rate = 0.003\n",
    "drop_rate = 0.3\n",
    "\n",
    "## Add multi camera angels (left/right) + Augmentation# Flip the Images for more data   \n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    batch_size = batch_size // 2 # to deal with image augmentation\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                \n",
    "                # IMAGES\n",
    "                img_center = prepImage(batch_sample[0], img_dir)\n",
    "                images.append(img_center)\n",
    "                \n",
    "                img_left = prepImage(batch_sample[1], img_dir)\n",
    "                images.append(img_left)\n",
    "                \n",
    "                img_right = prepImage(batch_sample[2], img_dir)\n",
    "                images.append(img_right)\n",
    "                \n",
    "                \n",
    "                # STEERING\n",
    "                steering_center = float(batch_sample[3])\n",
    "                angles.append(steering_center)\n",
    "\n",
    "                correction = 0.5 # this is a parameter to tune 0.2\n",
    "                steering_left = steering_center + correction\n",
    "                angles.append(steering_left)\n",
    "                steering_right = steering_center - correction\n",
    "                angles.append(steering_right)\n",
    "        \n",
    "            # AUGMENTATION (Flip the Images for more data)\n",
    "            augmented_images = []\n",
    "            augmented_angles = [] \n",
    "            for image, angle in zip(images, angles):\n",
    "                augmented_images.append(image)\n",
    "                augmented_angles.append(angle)\n",
    "                augmented_images.append(cv2.flip(image, 1))\n",
    "                augmented_angles.append(angle*-1.0)  \n",
    "\n",
    "            X_train = np.array(augmented_images)\n",
    "            y_train = np.array(augmented_angles)\n",
    "            \n",
    "            yield shuffle(X_train, y_train)\n",
    "            \n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=batch_size)\n",
    "validation_generator = generator(validation_samples, batch_size=batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "26/25 [===============================] - 38s - loss: 0.3349 - val_loss: 0.1841\n",
      "Epoch 2/5\n",
      "26/25 [===============================] - 38s - loss: 0.1831 - val_loss: 0.1832\n",
      "Epoch 3/5\n",
      "26/25 [===============================] - 37s - loss: 0.1833 - val_loss: 0.1837\n",
      "Epoch 4/5\n",
      "26/25 [===============================] - 38s - loss: 0.1829 - val_loss: 0.1855\n",
      "Epoch 5/5\n",
      "26/25 [===============================] - 37s - loss: 0.1832 - val_loss: 0.1851\n"
     ]
    }
   ],
   "source": [
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=5),\n",
    "    ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True, verbose=0)\n",
    "]\n",
    "\n",
    "img_h, img_w, ch = 160, 320, 3\n",
    "top_crop, bottom_crop = 50, 20\n",
    "left_crop, right_crop = 0, 0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# # Normalise\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(img_h,img_w,ch)))\n",
    "# Crop\n",
    "model.add(Cropping2D(cropping=((top_crop, bottom_crop), (left_crop, right_crop)) )) # , input_shape=(3,160,320)))\n",
    "\n",
    "# Conv Layer 1\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same')) # filters = 8\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "# Conv Layer 2\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same')) # filters = 16\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "# Conv Layer 3\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same')) # filters = 32\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "# Conv Layer 4\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same')) # filters = 64\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(drop_rate))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "#model.add(Dropout(drop_rate))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=learn_rate))\n",
    "\n",
    "# num train samples * 3 for centre, left, right camera, *2 for augmentation\n",
    "batch_step_factor = 3*2 # Need 3*2 to use full dataset each epoch\n",
    "\n",
    "history_object = model.fit_generator(train_generator,\n",
    "                    # num train samples * 3 for centre, left, right camera, *2 for augmentation\n",
    "                    steps_per_epoch= (len(train_samples)*batch_step_factor) / batch_size, \n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps= (len(validation_samples)*batch_step_factor) / batch_size, \n",
    "                    epochs=epochs,\n",
    "                    callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEZCAYAAACAZ8KHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f98aab4dac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Working code with left, right and centre images\n",
    "##\n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import sklearn\n",
    "# from sklearn.utils import shuffle\n",
    "\n",
    "# # Hyperparameters - leave these in this position\n",
    "# batch_size = 256\n",
    "# epochs = 5\n",
    "# learn_rate = 0.001\n",
    "# drop_rate = 0.3\n",
    "\n",
    "# ## Add multi camera angels (left/right) + Augmentation# Flip the Images for more data   \n",
    "\n",
    "# def generator(samples, batch_size=32):\n",
    "#     num_samples = len(samples)\n",
    "#     while 1: # Loop forever so the generator never terminates\n",
    "#         shuffle(samples)\n",
    "#         for offset in range(0, num_samples, batch_size):\n",
    "#             batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "#             images = []\n",
    "#             angles = []\n",
    "#             for batch_sample in batch_samples:\n",
    "                \n",
    "#                 # IMAGES\n",
    "#                 img_center = prepImage(batch_sample[0], img_dir)\n",
    "#                 images.append(img_center)\n",
    "                \n",
    "#                 img_left = prepImage(batch_sample[1], img_dir)\n",
    "#                 images.append(img_left)\n",
    "                \n",
    "#                 img_right = prepImage(batch_sample[2], img_dir)\n",
    "#                 images.append(img_right)\n",
    "                \n",
    "                \n",
    "#                 # STEERING\n",
    "#                 steering_center = float(batch_sample[3])\n",
    "#                 angles.append(steering_center)\n",
    "\n",
    "#                 correction = 0.2 # this is a parameter to tune\n",
    "#                 steering_left = steering_center + correction\n",
    "#                 angles.append(steering_left)\n",
    "#                 steering_right = steering_center - correction\n",
    "#                 angles.append(steering_right)\n",
    "\n",
    "\n",
    "#             # trim image to only see section with road\n",
    "#             X_train = np.array(images)\n",
    "#             y_train = np.array(angles)\n",
    "            \n",
    "#             yield shuffle(X_train, y_train)\n",
    "            \n",
    "# # compile and train the model using the generator function\n",
    "# train_generator = generator(train_samples, batch_size=batch_size)\n",
    "# validation_generator = generator(validation_samples, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "## Working code with centre images\n",
    "##\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import sklearn\n",
    "# from sklearn.utils import shuffle\n",
    "\n",
    "# # Hyperparameters - leave these in this position\n",
    "# batch_size = 256\n",
    "# epochs = 10\n",
    "# learn_rate = 0.001\n",
    "# drop_rate = 0.3\n",
    "\n",
    "# ## Add multi camera angels (left/right) + Augmentation# Flip the Images for more data   \n",
    "\n",
    "# def generator(samples, batch_size=32):\n",
    "#     num_samples = len(samples)\n",
    "#     while 1: # Loop forever so the generator never terminates\n",
    "#         shuffle(samples)\n",
    "#         for offset in range(0, num_samples, batch_size):\n",
    "#             batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "#             images = []\n",
    "#             angles = []\n",
    "#             for batch_sample in batch_samples:\n",
    "#                 name = img_dir + batch_sample[0].split('/')[-1]\n",
    "#                 # Update this for all camera angles\n",
    "#                 center_image = cv2.imread(name, 1) # 0 = grayscale, 1 = Colour\n",
    "#                 center_angle = float(batch_sample[3])\n",
    "#                 images.append(center_image)\n",
    "#                 angles.append(center_angle)\n",
    "\n",
    "#             # trim image to only see section with road\n",
    "#             X_train = np.array(images)\n",
    "#             y_train = np.array(angles)\n",
    "#             yield shuffle(X_train, y_train)\n",
    "            \n",
    "# # compile and train the model using the generator function\n",
    "# train_generator = generator(train_samples, batch_size=batch_size)\n",
    "# validation_generator = generator(validation_samples, batch_size=batch_size)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
